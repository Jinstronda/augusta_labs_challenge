# Incentives PostgreSQL Database Setup

Simple setup for loading public incentives data into a local PostgreSQL database.

## Prerequisites

1. **PostgreSQL** installed and running locally
   - Download from: https://www.postgresql.org/download/windows/
   - Default port: 5432
   - Set up the `postgres` user with a password

2. **Anaconda or Miniconda** installed with `turing0.1` environment
   - Download from: https://www.anaconda.com/download

## Quick Setup

### Step 1: Configure Database Credentials

Edit `config.env` and set your PostgreSQL password:

```env
DB_PASSWORD=your_actual_password
```

### Step 2: Activate Your Conda Environment

```batch
conda activate turing0.1
```

### Step 3: Install Required Packages

```batch
install_packages.bat
```

Or manually:
```batch
pip install -r requirements.txt
```

### Step 4: Run the Database Setup

```batch
python setup_postgres.py
```

This will:
- Create a database named `incentives_db`
- Create a table named `incentives` with all required columns
- Load data from `filtered_incentives0.3.csv`

### Step 5: Test the Connection (Optional)

```batch
python test_connection.py
```

## Database Schema

### Table: `incentives`

| Column | Type | Description |
|--------|------|-------------|
| `incentive_id` | VARCHAR(255) | Unique ID for each incentive (PRIMARY KEY) |
| `title` | TEXT | Title of the incentive |
| `description` | TEXT | Original description |
| `ai_description` | TEXT | Structured JSON description generated by AI |
| `document_urls` | TEXT | Links to associated documents |
| `publication_date` | TIMESTAMP | Publication date |
| `start_date` | TIMESTAMP | Start date |
| `end_date` | TIMESTAMP | End date |
| `total_budget` | NUMERIC | Total budget |
| `source_link` | TEXT | Link to official incentive page |
| `sector` | TEXT | *Empty - to be filled by LLM* |
| `geo_requirement` | TEXT | *Empty - to be filled by LLM* |
| `eligible_actions` | TEXT[] | *Empty - to be filled by LLM* |
| `funding_rate` | TEXT | *Empty - to be filled by LLM* |
| `investment_eur` | JSONB | *Empty - to be filled by LLM* |

## Connection Details

All connection details are stored in `config.env`:

- **Database:** `incentives_db`
- **Host:** `localhost`
- **Port:** `5432`
- **User:** `postgres`
- **Password:** (set in config.env)

## Querying the Database

You can connect to the database using any PostgreSQL client or Python:

```python
import psycopg2

conn = psycopg2.connect(
    dbname="incentives_db",
    user="postgres",
    password="joaopedro1",
    host="localhost",
    port="5432"
)

cursor = conn.cursor()
cursor.execute("SELECT COUNT(*) FROM incentives")
print(f"Total incentives: {cursor.fetchone()[0]}")
```

## Processing Incentives with GPT-5-mini

After loading the data, you can fill the empty LLM fields using GPT-5-mini:

### Step 1: Install OpenAI Package

```batch
pip install openai
```

### Step 2: Run the LLM Processing Script (Test Mode)

First, test with 2 records:

```batch
python fill_llm_fields.py
```

This will:
- Fetch 2 unprocessed incentives
- Send their descriptions to GPT-5-mini
- Parse the JSON response
- Update the database with extracted fields

### Step 3: Check Processing Status

```batch
python check_status.py
```

### Step 4: Process All Records

Once testing is successful, edit `fill_llm_fields.py` line 155:
```python
# Change from:
incentives = get_incentives_to_process(limit=2)

# To:
incentives = get_incentives_to_process(limit=None)  # Process all
```

## LLM Fields

The following columns are filled by GPT-5-mini:
- `sector` - Main thematic area (e.g., "Reabilitação Urbana", "PME")
- `geo_requirement` - Geographical eligibility (e.g., "Norte (NUTS II)")
- `eligible_actions` - Specific funded activities
- `funding_rate` - Co-financing percentage (e.g., "85% FEDER")
- `investment_eur` - Financial range (e.g., "Mínimo 250,000 EUR")
